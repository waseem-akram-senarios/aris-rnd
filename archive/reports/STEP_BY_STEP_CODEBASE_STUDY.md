# ARIS RAG System - Step-by-Step Deep Codebase Study
## Complete Systematic Analysis

**Date:** December 30, 2025  
**Total Code:** 131 Python files, 45,550+ lines  
**Analysis Type:** Comprehensive step-by-step architectural and implementation review

---

## ðŸ“‹ TABLE OF CONTENTS

1. [System Overview & Entry Points](#1-system-overview--entry-points)
2. [Application Initialization Flow](#2-application-initialization-flow)
3. [API Layer Architecture](#3-api-layer-architecture)
4. [Service Container Pattern](#4-service-container-pattern)
5. [Document Processing Pipeline](#5-document-processing-pipeline)
6. [Parser System Deep Dive](#6-parser-system-deep-dive)
7. [RAG System Core](#7-rag-system-core)
8. [Query Processing & Agentic RAG](#8-query-processing--agentic-rag)
9. [Vector Storage Architecture](#9-vector-storage-architecture)
10. [Image & OCR System](#10-image--ocr-system)
11. [Configuration Management](#11-configuration-management)
12. [Data Flow Diagrams](#12-data-flow-diagrams)
13. [Error Handling & Resilience](#13-error-handling--resilience)
14. [Design Patterns Used](#14-design-patterns-used)
15. [Key Algorithms](#15-key-algorithms)

---

## 1. SYSTEM OVERVIEW & ENTRY POINTS

### 1.1 Dual Application Architecture

The system has **two entry points**:

**A. Streamlit Web UI** (`app.py` â†’ `api/app.py`)
```python
# Root app.py is a thin wrapper
import runpy
runpy.run_path("api/app.py", run_name="__main__")
```

**B. FastAPI REST API** (`api/main.py`)
```python
app = FastAPI(
    title="ARIS RAG API - Minimal",
    description="Minimal API with 10 endpoints",
    version="2.0.0",
    lifespan=lifespan  # Startup/shutdown management
)
```

### 1.2 Entry Point Analysis

#### Streamlit Entry (`api/app.py`)
- **Purpose:** Interactive web UI for document processing and querying
- **Features:**
  - File upload with progress tracking
  - Real-time processing status
  - Interactive query interface
  - Metrics dashboard
  - Document library browser
- **Session State:** Manages RAG system, documents, chat history
- **Initialization:** Lazy loading of RAG system on first use

#### FastAPI Entry (`api/main.py`)
- **Purpose:** RESTful API for programmatic access
- **Features:**
  - 17 endpoints (Core, Query, Image, Page, Storage, Verification)
  - OpenAPI/Swagger documentation
  - Background task processing
  - CORS enabled
- **Initialization:** Service container created at startup via `lifespan`

### 1.3 RAG System Entry Point

**File:** `rag_system.py` (root level)
```python
from api.rag_system import RAGSystem
__all__ = ["RAGSystem"]
```

This is a **re-export** that points to the actual implementation in `api/rag_system.py`, maintaining backward compatibility.

---

## 2. APPLICATION INITIALIZATION FLOW

### 2.1 FastAPI Initialization Sequence

```
Application Start
    â”‚
    â–¼
lifespan(app) - Startup
    â”‚
    â”œâ”€â”€ [STEP 1] Log startup banner
    â”œâ”€â”€ [STEP 2] create_service_container()
    â”‚   â”‚
    â”‚   â”œâ”€â”€ Load ARISConfig defaults
    â”‚   â”œâ”€â”€ Check OpenSearch credentials
    â”‚   â”œâ”€â”€ Fallback to FAISS if no OpenSearch
    â”‚   â””â”€â”€ Get chunking parameters
    â”‚
    â”œâ”€â”€ [STEP 3] ServiceContainer.__init__()
    â”‚   â”‚
    â”‚   â”œâ”€â”€ [STEP 3.1] Initialize MetricsCollector
    â”‚   â”‚   â””â”€â”€ Tracks: processing, queries, tokens
    â”‚   â”‚
    â”‚   â”œâ”€â”€ [STEP 3.2] Initialize RAGSystem
    â”‚   â”‚   â”œâ”€â”€ Load embedding model (text-embedding-3-large)
    â”‚   â”‚   â”œâ”€â”€ Initialize TokenTextSplitter
    â”‚   â”‚   â”œâ”€â”€ Load document_index_map (if exists)
    â”‚   â”‚   â””â”€â”€ Initialize vector store (lazy)
    â”‚   â”‚
    â”‚   â”œâ”€â”€ [STEP 3.3] Initialize DocumentProcessor
    â”‚   â”‚   â””â”€â”€ Wraps RAGSystem for processing
    â”‚   â”‚
    â”‚   â””â”€â”€ [STEP 3.4] Initialize DocumentRegistry
    â”‚       â””â”€â”€ Load JSON registry from disk
    â”‚
    â””â”€â”€ [STEP 4] Application ready
        â””â”€â”€ Service container available via dependency injection
```

### 2.2 Service Container Creation

**Function:** `create_service_container()` in `api/service.py`

**Process:**
```python
1. Read configuration from ARISConfig
   â”œâ”€â”€ Model settings (embedding, LLM)
   â”œâ”€â”€ Vector store type
   â”œâ”€â”€ Chunking strategy
   â””â”€â”€ OpenSearch config

2. Validate OpenSearch availability
   â”œâ”€â”€ Check credentials exist
   â”œâ”€â”€ Check domain configured
   â””â”€â”€ Fallback to FAISS if missing

3. Get chunking parameters
   â””â”€â”€ From strategy (comprehensive/balanced/fast)

4. Create ServiceContainer instance
   â””â”€â”€ Pass all configuration
```

**Key Configuration Sources:**
- Environment variables (`.env`)
- `ARISConfig` class defaults
- Function parameters (override)

---

## 3. API LAYER ARCHITECTURE

### 3.1 FastAPI Application Structure

**File:** `api/main.py` (2,100+ lines)

**Architecture:**
- FastAPI app with lifespan management
- CORS middleware (all origins)
- Dependency injection for ServiceContainer
- 17 endpoints organized by tags

### 3.2 Endpoint Categories

#### Core Endpoints (5)
1. **GET /** - API information
2. **GET /health** - Health check
3. **GET /documents** - List all documents
4. **POST /documents** - Upload and process document
5. **DELETE /documents/{id}** - Delete document

#### Query Endpoints (1 unified)
6. **POST /query** - Unified query endpoint
   - Supports `type=text|image`
   - Supports `focus=all|important|summary|specific`
   - Supports `document_id` filtering
   - Query parameter overrides

#### Image Endpoints (4)
7. **GET /documents/{id}/images/all** - All images with OCR
8. **GET /documents/{id}/images** - Images summary by number
9. **GET /documents/{id}/images/{number}** - Specific image by number
10. **POST /documents/{id}/store/images** - Store images (with file upload)

#### Page Endpoints (1)
11. **GET /documents/{id}/pages/{page}** - Page information

#### Storage Endpoints (2)
12. **GET /documents/{id}/storage/status** - Storage status
13. **POST /documents/{id}/store/text** - Store text

#### Verification Endpoints (2)
14. **GET /documents/{id}/accuracy** - OCR accuracy check
15. **POST /documents/{id}/verify** - Verify document

#### Settings Endpoints (2 via router)
16. **GET /v1/config** - Get configuration
17. **POST /v1/config** - Update configuration

### 3.3 Request/Response Models

**File:** `api/schemas.py` (425 lines)

**Key Models:**
- `QueryRequest` - Query parameters with validation
- `QueryResponse` - Query results with citations
- `DocumentMetadata` - Complete document information
- `ImageQueryRequest/Response` - Image queries
- `PageInformationResponse` - Page content
- `StorageStatusResponse` - Storage state
- `SystemSettings` - Complete configuration

**Validation:**
- Pydantic validators for type safety
- Field constraints (min/max, ranges)
- Literal types for enums
- Optional vs required fields

---

## 4. SERVICE CONTAINER PATTERN

### 4.1 ServiceContainer Class

**File:** `api/service.py` (369 lines)

**Purpose:** Central dependency injection container

**Components Managed:**
1. `MetricsCollector` - Performance and usage metrics
2. `RAGSystem` - Core RAG implementation
3. `DocumentProcessor` - Document processing pipeline
4. `DocumentRegistry` - Persistent metadata storage

### 4.2 Initialization Sequence

```python
ServiceContainer.__init__()
  â”‚
  â”œâ”€â”€ [STEP 1] MetricsCollector()
  â”‚   â””â”€â”€ Initialize metrics tracking
  â”‚
  â”œâ”€â”€ [STEP 2] RAGSystem(config)
  â”‚   â”œâ”€â”€ Load embedding model
  â”‚   â”œâ”€â”€ Initialize text splitter
  â”‚   â”œâ”€â”€ Load document index map
  â”‚   â””â”€â”€ Prepare vector store (lazy init)
  â”‚
  â”œâ”€â”€ [STEP 3] DocumentProcessor(rag_system)
  â”‚   â””â”€â”€ Wraps RAGSystem for processing
  â”‚
  â””â”€â”€ [STEP 4] DocumentRegistry(path)
      â””â”€â”€ Load JSON registry from disk
```

### 4.3 Key Methods

**Document Management:**
- `get_document(id)` - Retrieve metadata
- `list_documents()` - List all documents
- `add_document(id, result)` - Save metadata
- `remove_document(id)` - Delete document

**Query Methods:**
- `query_text_only(...)` - Text-only queries
- `query_images_only(...)` - Image OCR queries
- `get_storage_status(id)` - Check storage state

**Design Pattern:** Service Locator / Dependency Injection

---

## 5. DOCUMENT PROCESSING PIPELINE

### 5.1 DocumentProcessor Class

**File:** `ingestion/document_processor.py` (760 lines)

**Purpose:** Orchestrates document parsing and processing

### 5.2 Processing Steps (Detailed)

```
Step 1: Validation & Preparation (0-10% progress)
  â”œâ”€â”€ Validate file type (.pdf, .txt, .docx, .doc)
  â”œâ”€â”€ Get file size
  â”œâ”€â”€ Check file exists
  â””â”€â”€ Initialize processing state

Step 2: Parser Selection & Parsing (10-45% progress)
  â”œâ”€â”€ Determine parser preference
  â”œâ”€â”€ ParserFactory.parse_with_fallback()
  â”‚   â”œâ”€â”€ Detect PDF type (text vs image-heavy)
  â”‚   â”œâ”€â”€ Try PyMuPDF (fast)
  â”‚   â”œâ”€â”€ Try Docling (OCR, structured)
  â”‚   â””â”€â”€ Try Textract (AWS OCR, fallback)
  â”‚
  â”œâ”€â”€ Extract text content
  â”œâ”€â”€ Extract images (if any)
  â”œâ”€â”€ Extract metadata
  â””â”€â”€ Get page-level information

Step 3: Chunking (45-60% progress)
  â”œâ”€â”€ TokenTextSplitter.split_text()
  â”‚   â”œâ”€â”€ Count tokens per chunk
  â”‚   â”œâ”€â”€ Split at token boundaries
  â”‚   â”œâ”€â”€ Preserve sentence boundaries
  â”‚   â””â”€â”€ Apply overlap
  â”‚
  â””â”€â”€ Adaptive chunking for large documents
      â””â”€â”€ Upscale chunk size if >200 chunks estimated

Step 4: Embedding & Storage (60-90% progress)
  â”œâ”€â”€ RAGSystem.add_documents_incremental()
  â”‚   â”œâ”€â”€ Generate embeddings (OpenAI)
  â”‚   â”œâ”€â”€ Create Document objects
  â”‚   â”œâ”€â”€ Store in vector store
  â”‚   â”‚   â”œâ”€â”€ OpenSearch: Per-document index
  â”‚   â”‚   â””â”€â”€ FAISS: Shared index
  â”‚   â””â”€â”€ Track metrics
  â”‚
  â””â”€â”€ Batch processing for large documents

Step 5: Image Storage (90-95% progress)
  â”œâ”€â”€ Extract images from parsed document
  â”œâ”€â”€ For each image:
  â”‚   â”œâ”€â”€ Extract OCR text
  â”‚   â”œâ”€â”€ Generate embedding from OCR text
  â”‚   â”œâ”€â”€ Create metadata
  â”‚   â””â”€â”€ Store in OpenSearch images index
  â”‚
  â””â”€â”€ Update document registry

Step 6: Registry Update (95-100% progress)
  â””â”€â”€ DocumentRegistry.save_document()
      â”œâ”€â”€ Save metadata to JSON
      â”œâ”€â”€ Track version history
      â””â”€â”€ Update processing state
```

### 5.3 ProcessingResult Dataclass

```python
@dataclass
class ProcessingResult:
    status: str  # 'success', 'failed', 'processing'
    document_name: str
    chunks_created: int
    tokens_extracted: int
    parser_used: Optional[str]
    error: Optional[str]
    processing_time: float
    extraction_percentage: float
    images_detected: bool
    image_count: int
```

**Note:** This dataclass does NOT have a `parsed_document` attribute. The parsed document is used during processing but not stored in the result.

---

## 6. PARSER SYSTEM DEEP DIVE

### 6.1 Parser Architecture

**Base Interface:** `parsers/base_parser.py`

```python
class BaseParser(ABC):
    @abstractmethod
    def parse(file_path, file_content) -> ParsedDocument:
        pass
    
    @abstractmethod
    def can_parse(file_path) -> bool:
        pass
```

**ParsedDocument Dataclass:**
```python
@dataclass
class ParsedDocument:
    text: str
    metadata: Dict
    pages: int
    images_detected: bool
    parser_used: str
    confidence: float
    extraction_percentage: float
    image_count: int
```

### 6.2 ParserFactory

**File:** `parsers/parser_factory.py` (395 lines)

**Parser Selection Logic:**

```
IF preferred_parser specified:
  â””â”€â”€ Use that parser (NO fallback)

ELSE (auto mode):
  1. Detect PDF type
     â”œâ”€â”€ Text-based PDF
     â””â”€â”€ Image-heavy PDF
  
  2. IF image-heavy:
     â””â”€â”€ Try Docling first (OCR capabilities)
  
  3. Try PyMuPDF (fastest)
     â”œâ”€â”€ Check quality (confidence > 0.7)
     â””â”€â”€ IF good â†’ Use it
  
  4. IF poor results:
     â”œâ”€â”€ Try Docling (structured content, OCR)
     â””â”€â”€ Compare results â†’ Use best
  
  5. Last resort:
     â””â”€â”€ Textract (if AWS available)
```

### 6.3 DoclingParser

**File:** `parsers/docling_parser.py` (1,684 lines)

**Key Features:**
- OCR for scanned PDFs
- Layout preservation
- Image extraction with OCR text
- ThreadPoolExecutor for non-blocking processing
- Configurable timeout (30 min default)
- Progress tracking

**Image Extraction Process:**
```python
1. DocumentConverter.convert(file_path)
   â””â”€â”€ Returns: DocumentResult

2. Extract images from document structure
   â”œâ”€â”€ For each page:
   â”‚   â”œâ”€â”€ Get images
   â”‚   â”œâ”€â”€ Extract OCR text
   â”‚   â””â”€â”€ Get metadata (bbox, page)
   â”‚
   â””â”€â”€ Create extracted_images list

3. Store in metadata
   â””â”€â”€ parsed_doc.metadata['extracted_images'] = [...]
```

**Image Marker Insertion:**
- Inserts `<!-- image -->` markers in text
- Helps identify image locations in text
- Used for context extraction

### 6.4 PyMuPDFParser

**File:** `parsers/pymupdf_parser.py`

**Key Features:**
- Fast text extraction (10x faster than Docling)
- High quality for text-based PDFs
- No OCR capability
- Lightweight dependencies

---

## 7. RAG SYSTEM CORE

### 7.1 RAGSystem Class

**File:** `api/rag_system.py` (5,600 lines)

**Purpose:** Core RAG implementation with advanced features

### 7.2 Initialization

```python
RAGSystem.__init__()
  â”œâ”€â”€ Load model configuration
  â”œâ”€â”€ Initialize embeddings (OpenAI or LocalHash)
  â”œâ”€â”€ Initialize TokenTextSplitter
  â”œâ”€â”€ Load document_index_map
  â”œâ”€â”€ Initialize metrics collector
  â””â”€â”€ Prepare LLM (OpenAI or Cerebras)
```

### 7.3 Key Methods

#### `process_documents()`
- Chunks documents using TokenTextSplitter
- Creates Document objects
- Handles PyMuPDF NoSessionContext errors
- Adaptive chunking for large documents

#### `add_documents_incremental()`
- Adds documents to vector store incrementally
- Progress tracking
- Batch processing
- Returns processing statistics

#### `query_with_rag()`
- Main query method
- Supports agentic RAG
- Hybrid search
- MMR retrieval
- Document filtering

#### `query_images()`
- Queries images index
- Searches OCR text
- Returns image results with metadata

### 7.4 Document Index Mapping

**Purpose:** Track which OpenSearch index contains which document

**Storage:** `vectorstore/document_index_map.json`

**Structure:**
```json
{
  "document_name.pdf": "aris-doc-uuid-123",
  "another_doc.pdf": "aris-doc-uuid-456"
}
```

**Usage:**
- Enables per-document indexing
- Supports document-specific queries
- Easier document deletion

---

## 8. QUERY PROCESSING & AGENTIC RAG

### 8.1 Query Flow

```
User Query
    â”‚
    â–¼
POST /query endpoint
    â”‚
    â”œâ”€â”€ Parse QueryRequest
    â”œâ”€â”€ Apply focus adjustments
    â”‚   â”œâ”€â”€ important â†’ 2x k, hybrid search
    â”‚   â”œâ”€â”€ summary â†’ k=20, MMR, summary prompt
    â”‚   â””â”€â”€ specific â†’ k=6, semantic only
    â”‚
    â–¼
ServiceContainer.query_text_only()
    â”‚
    â”œâ”€â”€ Set document filter (if document_id)
    â”œâ”€â”€ Set active_sources
    â””â”€â”€ Set document_index_map
    â”‚
    â–¼
RAGSystem.query_with_rag()
    â”‚
    â”œâ”€â”€ Check if agentic RAG enabled
    â”‚
    â”œâ”€â”€ IF Agentic RAG:
    â”‚   â””â”€â”€ QueryDecomposer.decompose_query()
    â”‚       â”œâ”€â”€ Check if simple query
    â”‚       â”œâ”€â”€ Call LLM (GPT-4o) for decomposition
    â”‚       â””â”€â”€ Return sub-queries (2-4)
    â”‚
    â”œâ”€â”€ FOR EACH (sub-)query:
    â”‚   â”œâ”€â”€ Generate query embedding
    â”‚   â”œâ”€â”€ Vector similarity search
    â”‚   â”œâ”€â”€ Keyword search (if hybrid)
    â”‚   â”œâ”€â”€ Combine results (weighted)
    â”‚   â””â”€â”€ Apply MMR (if enabled)
    â”‚
    â”œâ”€â”€ Deduplicate chunks
    â”œâ”€â”€ Rank by relevance
    â”œâ”€â”€ Limit to max chunks
    â”‚
    â””â”€â”€ Generate Answer
        â”œâ”€â”€ Build context from chunks
        â”œâ”€â”€ Create prompt
        â”œâ”€â”€ Call LLM (GPT-4o)
        â”œâ”€â”€ Extract citations
        â””â”€â”€ Return QueryResponse
```

### 8.2 Agentic RAG Implementation

**File:** `rag/query_decomposer.py` (248 lines)

**QueryDecomposer Class:**

```python
class QueryDecomposer:
    def decompose_query(question, max_subqueries=4) -> List[str]:
        1. Check if simple query
           â”œâ”€â”€ Very short (< 30 chars)
           â”œâ”€â”€ Single question mark
           â”œâ”€â”€ No conjunctions
           â””â”€â”€ Single question word
           
           IF simple â†’ Return [question]
        
        2. Call LLM for decomposition
           â”œâ”€â”€ System prompt: "Break down complex questions..."
           â”œâ”€â”€ User prompt: "Decompose: {question}"
           â”œâ”€â”€ Temperature: 0.3 (consistent)
           â””â”€â”€ Max tokens: 200
        
        3. Parse sub-queries
           â”œâ”€â”€ Split by newlines
           â”œâ”€â”€ Remove numbering/bullets
           â””â”€â”€ Validate (min length, not duplicate)
        
        4. Return sub-queries
           â””â”€â”€ Or [question] if decomposition fails
```

**Multi-Query Retrieval:**
```python
1. FOR EACH sub-query:
   â”œâ”€â”€ Generate embedding
   â”œâ”€â”€ Similarity search (k=6 per sub-query)
   â””â”€â”€ Collect chunks

2. Deduplicate chunks
   â”œâ”€â”€ Compare embeddings (threshold: 0.95)
   â””â”€â”€ Keep unique chunks

3. Rank by relevance to original query
   â””â”€â”€ Re-score against original

4. Limit to max_total_chunks (25)
   â””â”€â”€ Take top chunks

5. Generate answer
   â””â”€â”€ Use all chunks as context
```

### 8.3 Hybrid Search

**Implementation in OpenSearch:**

```python
1. Semantic Search
   â”œâ”€â”€ Vector similarity (knn search)
   â”œâ”€â”€ Weight: 0.75 (default)
   â””â”€â”€ Fetch: k * 2 candidates

2. Keyword Search
   â”œâ”€â”€ BM25 keyword matching
   â”œâ”€â”€ Weight: 0.25 (default)
   â””â”€â”€ Fetch: k * 2 candidates

3. Combine Results
   â”œâ”€â”€ Weighted score combination
   â”œâ”€â”€ Deduplicate
   â””â”€â”€ Sort by combined score

4. Return Top K
   â””â”€â”€ Best of both worlds
```

### 8.4 MMR (Maximal Marginal Relevance)

**Purpose:** Reduce redundancy in retrieved chunks

**Algorithm:**
```python
1. Fetch more candidates (fetch_k=50)
2. Select most relevant first
3. FOR remaining k-1:
   â”œâ”€â”€ Calculate relevance to query
   â”œâ”€â”€ Calculate similarity to selected
   â””â”€â”€ MMR score = Î» * relevance - (1-Î») * similarity
4. Select highest MMR score
5. Repeat until k chunks selected
```

**Parameters:**
- `lambda_mult`: 0.35 (balanced relevance/diversity)
- `fetch_k`: 50 (candidate pool)

---

## 9. VECTOR STORAGE ARCHITECTURE

### 9.1 Dual Index System

**Text Index:**
- Name: `aris-rag-index` (default) or `aris-doc-{id}` (per-document)
- Stores: Text chunks with embeddings
- Search: Semantic + keyword (hybrid)

**Images Index:**
- Name: `aris-rag-images-index` (shared)
- Stores: Images with OCR text embeddings
- Search: OCR text search

### 9.2 OpenSearchVectorStore

**File:** `vectorstores/opensearch_store.py` (986 lines)

**Key Features:**
- AWS OpenSearch Service integration
- Per-document index support
- Hybrid search (semantic + keyword)
- MMR retrieval
- Incremental document addition
- **Dimension mismatch auto-fix** (NEW)

**Index Structure:**
```json
{
  "mappings": {
    "properties": {
      "text": {"type": "text"},
      "embedding": {
        "type": "knn_vector",
        "dimension": 3072  // text-embedding-3-large
      },
      "metadata": {
        "source": {"type": "keyword"},
        "page": {"type": "integer"},
        "chunk_index": {"type": "integer"}
      }
    }
  }
}
```

**Connection Management:**
```python
1. Get AWS credentials from .env
2. Create OpenSearch client (boto3)
3. Describe domain to get endpoint
4. Initialize LangChain OpenSearchVectorSearch
5. Try AWS4Auth (primary)
6. Fallback to HTTP Basic Auth
```

**Dimension Mismatch Auto-Fix:**
```python
# In add_documents() and from_documents()
IF dimension mismatch error detected:
  1. Log warning
  2. Get current embedding dimension
  3. Delete old index
  4. Recreate vectorstore (creates new index)
  5. Retry adding documents
  6. Success!
```

### 9.3 OpenSearchImagesStore

**File:** `vectorstores/opensearch_images_store.py` (693 lines)

**Purpose:** Separate index for image OCR data

**Key Methods:**
- `store_image()` - Store single image with OCR
- `get_images_by_source()` - Get all images for document
- `query_images()` - Search images by OCR text
- `delete_by_source()` - Delete all images for document
- `count_images_by_source()` - Count images for document

**Image Metadata Structure:**
```python
{
    'source': 'document_name.pdf',
    'image_number': 1,
    'page': 1,
    'ocr_text': 'Extracted text from image',
    'ocr_text_length': 150,
    'extraction_method': 'docling',
    'metadata': {
        'marker_detected': True,
        'full_chunk': '...',
        'context_before': '...'
    }
}
```

### 9.4 VectorStoreFactory

**File:** `vectorstores/vector_store_factory.py` (328 lines)

**Purpose:** Factory pattern for vector store creation

**Supported Types:**
- `faiss` - Local FAISS vector store
- `opensearch` - AWS OpenSearch Service

**Methods:**
- `create_vector_store()` - Create new store
- `load_vector_store()` - Load existing store

---

## 10. IMAGE & OCR SYSTEM

### 10.1 Image Extraction Flow

```
Document Parsing (Docling)
    â”‚
    â”œâ”€â”€ Extract images from PDF
    â”œâ”€â”€ Run OCR on each image
    â”œâ”€â”€ Extract OCR text
    â”‚
    â–¼
Store in OpenSearch Images Index
    â”‚
    â”œâ”€â”€ For each image:
    â”‚   â”œâ”€â”€ Extract OCR text
    â”‚   â”œâ”€â”€ Generate embedding (from OCR text)
    â”‚   â”œâ”€â”€ Create metadata:
    â”‚   â”‚   â”œâ”€â”€ source (document name)
    â”‚   â”‚   â”œâ”€â”€ page number
    â”‚   â”‚   â”œâ”€â”€ image_number
    â”‚   â”‚   â”œâ”€â”€ extraction_method
    â”‚   â”‚   â””â”€â”€ ocr_text
    â”‚   â””â”€â”€ Store in OpenSearch
    â”‚
    â””â”€â”€ Update document registry
        â””â”€â”€ images_stored count
```

### 10.2 Image Storage Endpoint

**Endpoint:** `POST /documents/{id}/store/images`

**Process:**
```python
1. Check if file provided
   â”œâ”€â”€ IF file provided:
   â”‚   â”œâ”€â”€ Save to temp file
   â”‚   â”œâ”€â”€ Parse with DoclingParser directly
   â”‚   â”œâ”€â”€ Extract images from parsed_doc.metadata
   â”‚   â””â”€â”€ Store in OpenSearch
   â”‚
   â””â”€â”€ IF no file:
       â””â”€â”€ Check existing images in registry

2. Store images
   â”œâ”€â”€ For each extracted image:
   â”‚   â”œâ”€â”€ Get OCR text
   â”‚   â”œâ”€â”€ Generate embedding
   â”‚   â”œâ”€â”€ Create Document with metadata
   â”‚   â””â”€â”€ Store in images index
   â”‚
   â””â”€â”€ Update document registry

3. Return ImageStorageResponse
   â””â”€â”€ images_stored count, status, message
```

**Fallback Logic:**
- If `extracted_images` is empty but images detected:
  - Create synthetic image entries from text
  - Split by page blocks if available
  - Mark as `extraction_method='docling_ocr_fallback'`

### 10.3 Image Query Endpoints

**GET /documents/{id}/images**
- Returns summary with image numbers and OCR text lengths

**GET /documents/{id}/images/{number}**
- Returns specific image by number with full OCR text

**GET /documents/{id}/images/all**
- Returns all images with complete OCR text

---

## 11. CONFIGURATION MANAGEMENT

### 11.1 ARISConfig Class

**File:** `config/settings.py` (157 lines)

**Configuration Groups:**

**1. Model Configuration:**
```python
EMBEDDING_MODEL: 'text-embedding-3-large'  # 3072 dims
OPENAI_MODEL: 'gpt-4o'  # Latest GPT-4o
CEREBRAS_MODEL: 'llama-3.3-70b'  # 70B parameters
USE_CEREBRAS: False  # Default to OpenAI
```

**2. Vector Store:**
```python
VECTOR_STORE_TYPE: 'opensearch'  # or 'faiss'
AWS_OPENSEARCH_DOMAIN: 'intelycx-waseem-os'
AWS_OPENSEARCH_INDEX: 'aris-rag-index'
AWS_OPENSEARCH_REGION: 'us-east-2'
```

**3. Chunking:**
```python
CHUNKING_STRATEGY: 'comprehensive'
DEFAULT_CHUNK_SIZE: 384  # tokens
DEFAULT_CHUNK_OVERLAP: 120  # tokens
```

**4. Retrieval:**
```python
DEFAULT_RETRIEVAL_K: 12  # chunks
DEFAULT_USE_MMR: True
DEFAULT_MMR_FETCH_K: 50
DEFAULT_MMR_LAMBDA: 0.35
DEFAULT_SEARCH_MODE: 'hybrid'
```

**5. Agentic RAG:**
```python
DEFAULT_USE_AGENTIC_RAG: True
DEFAULT_MAX_SUB_QUERIES: 4
DEFAULT_CHUNKS_PER_SUBQUERY: 6
DEFAULT_MAX_TOTAL_CHUNKS: 25
DEFAULT_DEDUPLICATION_THRESHOLD: 0.95
```

### 11.2 Configuration Methods

**Class Methods:**
- `get_model_config()` - Model settings
- `get_chunking_config()` - Chunking parameters
- `get_opensearch_config()` - OpenSearch settings
- `get_hybrid_search_config()` - Search weights
- `get_agentic_rag_config()` - Agentic RAG settings

---

## 12. DATA FLOW DIAGRAMS

### 12.1 Complete Document Upload Flow

```
User Uploads PDF
    â”‚
    â–¼
POST /documents (FastAPI)
    â”‚
    â”œâ”€â”€ Validate file type
    â”œâ”€â”€ Generate document_id (UUID)
    â”œâ”€â”€ Save file to disk
    â”œâ”€â”€ Calculate file hash (SHA256)
    â”œâ”€â”€ Check for duplicates
    â”‚
    â–¼
Background Task: DocumentProcessor.process_document()
    â”‚
    â”œâ”€â”€ [Step 1] Validation (0-10%)
    â”‚   â””â”€â”€ File type, size, existence
    â”‚
    â”œâ”€â”€ [Step 2] Parsing (10-45%)
    â”‚   â””â”€â”€ ParserFactory.parse_with_fallback()
    â”‚       â”œâ”€â”€ Detect PDF type
    â”‚       â”œâ”€â”€ Try parsers in order
    â”‚       â””â”€â”€ Return ParsedDocument
    â”‚
    â”œâ”€â”€ [Step 3] Chunking (45-60%)
    â”‚   â””â”€â”€ TokenTextSplitter.split_text()
    â”‚       â”œâ”€â”€ Split into chunks (384 tokens)
    â”‚       â”œâ”€â”€ Overlap (120 tokens)
    â”‚       â””â”€â”€ Preserve sentences
    â”‚
    â”œâ”€â”€ [Step 4] Embedding & Storage (60-90%)
    â”‚   â””â”€â”€ RAGSystem.add_documents_incremental()
    â”‚       â”œâ”€â”€ Generate embeddings (OpenAI)
    â”‚       â”œâ”€â”€ Store in OpenSearch (per-doc index)
    â”‚       â””â”€â”€ Track metrics
    â”‚
    â”œâ”€â”€ [Step 5] Image Storage (90-95%)
    â”‚   â””â”€â”€ _store_images_in_opensearch()
    â”‚       â”œâ”€â”€ Extract OCR text
    â”‚       â”œâ”€â”€ Generate embeddings
    â”‚       â””â”€â”€ Store in images index
    â”‚
    â””â”€â”€ [Step 6] Registry Update (95-100%)
        â””â”€â”€ DocumentRegistry.save_document()
            â””â”€â”€ Save metadata to JSON
```

### 12.2 Complete Query Flow

```
User Query (POST /query)
    â”‚
    â–¼
Parse QueryRequest
    â”‚
    â”œâ”€â”€ Apply focus adjustments
    â”‚   â”œâ”€â”€ important â†’ 2x k, hybrid
    â”‚   â”œâ”€â”€ summary â†’ k=20, MMR, summary prompt
    â”‚   â””â”€â”€ specific â†’ k=6, semantic
    â”‚
    â–¼
ServiceContainer.query_text_only()
    â”‚
    â”œâ”€â”€ Set document filter (if document_id)
    â”œâ”€â”€ Set active_sources
    â””â”€â”€ Set document_index_map
    â”‚
    â–¼
RAGSystem.query_with_rag()
    â”‚
    â”œâ”€â”€ Check agentic RAG
    â”‚
    â”œâ”€â”€ IF Agentic RAG:
    â”‚   â””â”€â”€ QueryDecomposer.decompose_query()
    â”‚       â”œâ”€â”€ Check if simple
    â”‚       â”œâ”€â”€ Call LLM for decomposition
    â”‚       â””â”€â”€ Return sub-queries
    â”‚
    â”œâ”€â”€ FOR EACH (sub-)query:
    â”‚   â”œâ”€â”€ Generate query embedding
    â”‚   â”œâ”€â”€ Vector similarity search
    â”‚   â”œâ”€â”€ Keyword search (if hybrid)
    â”‚   â”œâ”€â”€ Combine results (weighted)
    â”‚   â””â”€â”€ Apply MMR (if enabled)
    â”‚
    â”œâ”€â”€ Deduplicate chunks
    â”œâ”€â”€ Rank by relevance
    â”œâ”€â”€ Limit to max chunks
    â”‚
    â””â”€â”€ Generate Answer
        â”œâ”€â”€ Build context from chunks
        â”œâ”€â”€ Create prompt
        â”œâ”€â”€ Call LLM (GPT-4o)
        â”œâ”€â”€ Extract citations
        â””â”€â”€ Return QueryResponse
```

---

## 13. ERROR HANDLING & RESILIENCE

### 13.1 Error Handling Strategy

**Graceful Degradation:**
- Fallback parsers (PyMuPDF â†’ Docling â†’ Textract)
- Fallback to FAISS if OpenSearch fails
- Continue processing on non-critical errors

**Dimension Mismatch Handling:**
- **FAISS:** Auto-recreate on mismatch
- **OpenSearch:** Auto-delete and recreate index
- Both: Clear error messages with solutions

**Parser Errors:**
- Timeout handling (Docling: 30 min)
- Progress tracking during long operations
- Error recovery with fallback parsers

### 13.2 Error Types

**Validation Errors:**
- File type validation
- Request parameter validation
- Pydantic model validation

**Processing Errors:**
- Parser failures
- Timeout errors
- OCR extraction failures

**Storage Errors:**
- OpenSearch connection failures
- Index creation failures
- Document not found

### 13.3 Logging

**Comprehensive logging throughout:**
- Structured logging with levels
- Progress tracking
- Error details with stack traces
- Performance metrics

**Log Files:**
- `logs/fastapi.log` - API logs
- `logs/document_processor.log` - Processing logs
- Console output for real-time monitoring

---

## 14. DESIGN PATTERNS USED

### 14.1 Service Container Pattern
- Centralized initialization
- Dependency injection
- Lifecycle management

### 14.2 Factory Pattern
- `ParserFactory` - Parser selection
- `VectorStoreFactory` - Vector store creation

### 14.3 Strategy Pattern
- Chunking strategies (precise, balanced, comprehensive)
- Search modes (semantic, keyword, hybrid)

### 14.4 Repository Pattern
- `DocumentRegistry` - Abstracted persistence
- Easy to swap backends

### 14.5 Template Method Pattern
- `BaseParser` - Common parsing interface
- Parser-specific implementations

---

## 15. KEY ALGORITHMS

### 15.1 Adaptive Chunking

**Purpose:** Optimize chunk size for large documents

**Algorithm:**
```python
1. Estimate total tokens
2. Calculate estimated chunks
3. IF estimated_chunks > 200 AND chunk_size <= 512:
   â”œâ”€â”€ Calculate target chunk size
   â”œâ”€â”€ Limit to 512-1536 range
   â”œâ”€â”€ Calculate proportional overlap
   â””â”€â”€ Use adaptive splitter
4. ELSE:
   â””â”€â”€ Use configured splitter
```

### 15.2 Query Decomposition

**Purpose:** Break complex queries into sub-queries

**Algorithm:**
```python
1. Check if simple query
   â””â”€â”€ IF simple â†’ Return [question]

2. Call LLM for decomposition
   â”œâ”€â”€ System prompt with examples
   â”œâ”€â”€ User prompt: "Decompose: {question}"
   â””â”€â”€ Temperature: 0.3

3. Parse response
   â”œâ”€â”€ Split by newlines
   â”œâ”€â”€ Remove numbering/bullets
   â””â”€â”€ Validate (min length, not duplicate)

4. Return sub-queries
   â””â”€â”€ Or [question] if fails
```

### 15.3 MMR Algorithm

**Purpose:** Diverse result retrieval

**Algorithm:**
```python
1. Fetch candidates (fetch_k=50)
2. Select most relevant first
3. FOR remaining k-1:
   â”œâ”€â”€ relevance = similarity(query, doc)
   â”œâ”€â”€ max_similarity = max(similarity(doc, selected))
   â””â”€â”€ score = Î» * relevance - (1-Î») * max_similarity
4. Select highest score
5. Repeat until k selected
```

---

## 16. FILE ORGANIZATION

### 16.1 Current Structure

```
aris/
â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”œâ”€â”€ main.py            # Main API (17 endpoints)
â”‚   â”œâ”€â”€ app.py             # Streamlit UI
â”‚   â”œâ”€â”€ service.py         # Service container
â”‚   â”œâ”€â”€ schemas.py         # Pydantic models
â”‚   â””â”€â”€ rag_system.py      # Core RAG (5,600 lines)
â”‚
â”œâ”€â”€ parsers/               # Document parsers
â”‚   â”œâ”€â”€ base_parser.py     # Base interface
â”‚   â”œâ”€â”€ docling_parser.py  # Advanced OCR (1,684 lines)
â”‚   â”œâ”€â”€ pymupdf_parser.py # Fast parser
â”‚   â””â”€â”€ parser_factory.py  # Parser selection
â”‚
â”œâ”€â”€ vectorstores/          # Vector storage
â”‚   â”œâ”€â”€ opensearch_store.py      # Text storage (986 lines)
â”‚   â”œâ”€â”€ opensearch_images_store.py  # Image storage (693 lines)
â”‚   â””â”€â”€ vector_store_factory.py  # Factory
â”‚
â”œâ”€â”€ ingestion/             # Document processing
â”‚   â””â”€â”€ document_processor.py  # Processing pipeline (760 lines)
â”‚
â”œâ”€â”€ rag/                   # RAG components
â”‚   â””â”€â”€ query_decomposer.py  # Agentic RAG (248 lines)
â”‚
â”œâ”€â”€ storage/               # Persistence
â”‚   â””â”€â”€ document_registry.py  # JSON registry (309 lines)
â”‚
â”œâ”€â”€ config/                # Configuration
â”‚   â””â”€â”€ settings.py       # ARISConfig (157 lines)
â”‚
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ tokenizer.py      # Token-aware splitting
â”‚   â”œâ”€â”€ chunking_strategies.py  # Chunking presets
â”‚   â””â”€â”€ ocr_verifier.py   # OCR verification
â”‚
â”œâ”€â”€ scripts/               # Scripts
â”‚   â”œâ”€â”€ all_scripts/      # All .sh files (45 files)
â”‚   â””â”€â”€ utilities/        # Python utilities
â”‚
â”œâ”€â”€ tests/                 # Test suite (78 files)
â”œâ”€â”€ documentation/         # Documentation
â””â”€â”€ reports/              # Test reports
```

### 16.2 Root Directory (Clean)

**Essential Files Only:**
- `app.py` - Streamlit entry point
- `rag_system.py` - RAG re-export
- `README.md` - Project documentation
- `Dockerfile`, `docker-compose.yml` - Docker config
- `pytest.ini` - Test config
- `.env` - Environment variables

**All other files organized in folders**

---

## 17. KEY INSIGHTS & FINDINGS

### 17.1 Architecture Strengths

1. **Clear Separation of Concerns**
   - API layer separate from business logic
   - Service container for dependency management
   - Parser abstraction for flexibility

2. **Production-Ready Features**
   - Comprehensive error handling
   - Logging throughout
   - Health checks
   - Graceful degradation

3. **Advanced RAG Capabilities**
   - Agentic RAG with query decomposition
   - Hybrid search (semantic + keyword)
   - MMR for diversity
   - Multi-modal (text + images)

4. **Flexible Configuration**
   - Environment-based
   - Sensible defaults
   - Easy to tune

### 17.2 Recent Improvements

1. **Dimension Mismatch Auto-Fix**
   - Automatically handles embedding dimension changes
   - Deletes and recreates indexes
   - No manual intervention needed

2. **Per-Document Indexing**
   - Document isolation
   - Better query performance
   - Easier deletion

3. **Image OCR Storage**
   - Separate index for images
   - Query by image number
   - Full OCR text retrieval

### 17.3 Code Quality

**Strengths:**
- Type hints throughout
- Comprehensive docstrings
- Error handling
- Logging

**Areas for Improvement:**
- More unit tests
- Integration test coverage
- CI/CD pipeline
- Monitoring (Prometheus/Grafana)

---

## 18. SYSTEM METRICS

### 18.1 Code Statistics
- **Total Python Files:** 131
- **Total Python Lines:** 45,550+
- **API Endpoints:** 17
- **Parsers:** 5
- **Vector Stores:** 2 (OpenSearch, FAISS)
- **Test Files:** 78

### 18.2 Component Sizes
- `api/rag_system.py`: ~5,600 lines (core RAG)
- `parsers/docling_parser.py`: ~1,684 lines (advanced parser)
- `vectorstores/opensearch_store.py`: ~986 lines
- `api/main.py`: ~2,100 lines (API endpoints)
- `api/schemas.py`: ~425 lines (data models)
- `ingestion/document_processor.py`: ~760 lines

---

## 19. DEPENDENCIES & INTEGRATIONS

### 19.1 External Services
- **OpenSearch (AWS)** - Vector + keyword search
- **OpenAI** - Embeddings & LLM
- **AWS Services** - OpenSearch, Textract (optional), S3 (optional)

### 19.2 Key Python Packages
- `fastapi` - REST API framework
- `streamlit` - Web UI framework
- `langchain` - RAG framework
- `langchain-openai` - OpenAI integration
- `langchain-community` - OpenSearch integration
- `docling` - Advanced PDF parsing
- `pymupdf` - Fast PDF parsing
- `boto3` - AWS SDK
- `pydantic` - Data validation
- `tiktoken` - Token counting

---

## 20. CONCLUSION

### System Maturity: **Production-Grade (8.5/10)**

**Architecture:** 9/10
- Well-designed with clear patterns
- Modular and extensible
- Good separation of concerns

**Features:** 9/10
- Advanced RAG capabilities
- Multi-modal support
- OCR integration
- Comprehensive API

**Code Quality:** 8/10
- Good structure
- Type hints
- Documentation
- Error handling

**Deployment:** 8/10
- Docker-based
- Automated deployment
- Health checks
- Resource management

**Overall Assessment:** **8.5/10**

This is a well-designed, production-ready RAG system with advanced features and good architectural practices. The system demonstrates:

- âœ… Professional architecture
- âœ… Advanced RAG capabilities
- âœ… Multi-modal support
- âœ… Production deployment
- âœ… Comprehensive API (17 endpoints)
- âœ… Robust error handling
- âœ… Flexible configuration
- âœ… Recent improvements (dimension mismatch fix, per-document indexing)

With additional testing, monitoring, and security enhancements, this would be a 10/10 enterprise-grade system.

---

**Analysis Complete**  
**Date:** December 30, 2025  
**Total Components Analyzed:** 50+  
**Lines of Code Reviewed:** 45,550+  
**Documentation Created:** Complete step-by-step analysis
